{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crNg4tQ3R61i",
    "outputId": "38b1fa51-2f8e-48e6-8274-9b7077626645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, vaderSentiment, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas vaderSentiment textblob transformers torch nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "c1b3b66be96148079d85d15962e2781e",
      "64d0c41d0db74bed98ce3d8218e4de81",
      "5a35c1f08d594b1682e014ed0708a8ba",
      "48f32ead2dda4bd481a045397a84b202",
      "9a0f2b4925d94a12a499416778c71d44",
      "73470285cda246bbb5d6e423be32ff1d",
      "c6385d99073f48bcbbbc57a96b479656",
      "382d5d057119478b8f65cf4aa506e4f1",
      "c1e193c0722948a6bf20627d450f8b87",
      "2d6f1eeabf8b4f74a1ecc7839c5d153b",
      "8e7aaae856ef4ba994f1a24bcc5f8afb",
      "02e7865465194f6784f23bc21235f146",
      "4e0676e8e1934ff183676dfc77f9176a",
      "55ee1580b3e54b5b87bd7932e4c0d22c",
      "da9ddd4d9ba2471b88bb114e6f2635a6",
      "aae50b5852ad49519c0b42acd39f09e8",
      "6a3562cf6fb147b5b1208d936edbe197",
      "70526d7d69c94dc4ad5917a7081b2bb2",
      "5380986613914047a5d4ee8f4995691d",
      "deaa137ccb054991b375a155b3e854b6",
      "22df7a8ac4b74f49aa3a1957c738013e",
      "fd4a1eed904e4bd6b8961d28876641e9",
      "1a6318da54874b1f87cd1b26a1d1934e",
      "c13fbce79c81453383c12f1b08b7f262",
      "24cbbdb73e0b40b587a4be3aa706073c",
      "f7261e6fe48a4af4a323812f3e68f458",
      "f5562c2c16f64268bc9615e40983e090",
      "8150c880b6fe4b30a86dce827012355d",
      "379d040089e14e248234ce97d9c353ce",
      "0c5cb673a849410ab3ea3b3e987977d7",
      "fb3d1bb0516b498490d0c582b2a1626f",
      "bc72475ac96d4461864788c770e3fa62",
      "b9574a2aa8c54571b6f1957af466ad44",
      "91592f868c2245eb8123fd1a4c435d4f",
      "d93607a96bdc4b34a38fd3670ade987f",
      "8df9829d730644079c8358ae0b940317",
      "bee47488c1a54846b14c4db290e23c09",
      "38c4e6fbfb564f9684018d07afbf74a4",
      "db45350df87d4400b82faeb7e240089b",
      "908f002abafb4a4ab01a8048b6e5d2ec",
      "66b9f364ac1b4cdb8c2ef71712d3b43c",
      "ff144d4ca3204672a66caf8e6176639c",
      "84bbe2b129bd40fbbb6238e6d98738f0",
      "b6e3a82d263d4d52bee50ff29b41c368"
     ]
    },
    "id": "WdqvLZYmRpLg",
    "outputId": "68d3b7ff-9783-483e-b3fe-c6ed46e4d50d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b3b66be96148079d85d15962e2781e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e7865465194f6784f23bc21235f146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6318da54874b1f87cd1b26a1d1934e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91592f868c2245eb8123fd1a4c435d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed and saved in 'sentiment_analysis_mahakumbh.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load dataset\n",
    "input_file = \"english_mahakumbh_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop rows with missing text values\n",
    "df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "# Convert 'text' to string to avoid errors\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "\n",
    "# Initialize sentiment analysis models\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "bert_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function for VADER sentiment analysis\n",
    "def get_vader_score(text):\n",
    "    return vader_analyzer.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "# Function for TextBlob sentiment analysis\n",
    "def get_textblob_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Function for BERT sentiment analysis\n",
    "def get_bert_score(text):\n",
    "    text = text[:512]  # Limit text length to 512 tokens for BERT\n",
    "    if not text:  # Handle empty strings\n",
    "        return 0\n",
    "\n",
    "    result = bert_analyzer(text)\n",
    "    label = result[0][\"label\"].lower()\n",
    "    score = result[0][\"score\"]\n",
    "\n",
    "    return score if label == \"positive\" else -score if label == \"negative\" else 0\n",
    "\n",
    "# Apply sentiment analysis functions\n",
    "df[\"VADER Score\"] = df[\"text\"].apply(get_vader_score)\n",
    "df[\"TextBlob Score\"] = df[\"text\"].apply(get_textblob_score)\n",
    "df[\"BERT Score\"] = df[\"text\"].apply(get_bert_score)\n",
    "\n",
    "# Compute average sentiment score\n",
    "df[\"Average Sentiment\"] = df[[\"VADER Score\", \"TextBlob Score\", \"BERT Score\"]].mean(axis=1)\n",
    "\n",
    "# Function to assign sentiment label\n",
    "def assign_label(score):\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply sentiment labeling\n",
    "df[\"Sentiment Label\"] = df[\"Average Sentiment\"].apply(assign_label)\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[[\"pseudo_id\", \"text\", \"VADER Score\", \"TextBlob Score\", \"BERT Score\", \"Average Sentiment\", \"Sentiment Label\"]]\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"sentiment_analysis_mahakumbh.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis completed and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d11aqRQAEgKT",
    "outputId": "b529b282-4177-45df-ce7e-8c8f08eab33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m204.8/244.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBWx4h50oc14",
    "outputId": "3b34657b-570f-45dc-8132-277381dfea8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "<ipython-input-5-8515661f0f8f>:34: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=df, x=\"Sentiment Label\", order=[\"Positive\", \"Neutral\", \"Negative\"], palette=\"pastel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DOCX report saved as 'Mahakumbh_Sentiment_Analysis_Report.docx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# --- Setup ---\n",
    "input_csv = \"sentiment_analysis_mahakumbh.csv\"\n",
    "output_dir = \"sentiment_report_visuals\"\n",
    "report_file = \"Mahakumbh_Sentiment_Analysis_Report.docx\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Count sentiment classes\n",
    "sentiment_counts = df[\"Sentiment Label\"].value_counts()\n",
    "total = len(df)\n",
    "positive_count = sentiment_counts.get(\"Positive\", 0)\n",
    "neutral_count = sentiment_counts.get(\"Neutral\", 0)\n",
    "negative_count = sentiment_counts.get(\"Negative\", 0)\n",
    "dominant_sentiment = sentiment_counts.idxmax()\n",
    "\n",
    "# --- Generate Bar Chart ---\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x=\"Sentiment Label\", order=[\"Positive\", \"Neutral\", \"Negative\"], palette=\"pastel\")\n",
    "plt.title(\"Sentiment Distribution (Bar Chart)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "bar_chart_path = f\"{output_dir}/sentiment_bar_chart.png\"\n",
    "plt.savefig(bar_chart_path)\n",
    "plt.close()\n",
    "\n",
    "# --- Generate Pie Chart ---\n",
    "colors = [\"#8fd694\", \"#f7d794\", \"#ff6b6b\"]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct=\"%1.1f%%\", startangle=140, colors=colors)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Sentiment Distribution (Pie Chart)\")\n",
    "pie_chart_path = f\"{output_dir}/sentiment_pie_chart.png\"\n",
    "plt.savefig(pie_chart_path)\n",
    "plt.close()\n",
    "\n",
    "# --- Generate Word Clouds ---\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def generate_wordcloud(sentiment_label, color_map):\n",
    "    text_data = \" \".join(df[df[\"Sentiment Label\"] == sentiment_label][\"text\"].dropna().astype(str))\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color=\"white\",\n",
    "        stopwords=STOPWORDS.union(stop_words),\n",
    "        colormap=color_map\n",
    "    ).generate(text_data)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud - {sentiment_label}\")\n",
    "    cloud_path = f\"{output_dir}/wordcloud_{sentiment_label.lower()}.png\"\n",
    "    plt.savefig(cloud_path)\n",
    "    plt.close()\n",
    "    return cloud_path\n",
    "\n",
    "positive_wc = generate_wordcloud(\"Positive\", \"Greens\")\n",
    "neutral_wc = generate_wordcloud(\"Neutral\", \"Blues\")\n",
    "negative_wc = generate_wordcloud(\"Negative\", \"Reds\")\n",
    "\n",
    "# --- Create DOCX Report ---\n",
    "doc = Document()\n",
    "doc.add_heading(\"Sentiment Analysis Report\", 0)\n",
    "\n",
    "# Overview\n",
    "doc.add_heading(\"Overview\", level=1)\n",
    "doc.add_paragraph(\n",
    "    f\"This report summarizes sentiment analysis results from the file '{input_csv}', \"\n",
    "    f\"which includes {total} text entries. Sentiment labels were generated using VADER, \"\n",
    "    f\"TextBlob, and BERT scores. The final label is based on the average sentiment score.\"\n",
    ")\n",
    "\n",
    "# Distribution Charts\n",
    "doc.add_heading(\"Sentiment Distribution\", level=1)\n",
    "doc.add_picture(bar_chart_path, width=Inches(5.5))\n",
    "doc.add_paragraph(\"Bar chart showing the count of Positive, Neutral, and Negative sentiments.\")\n",
    "\n",
    "doc.add_picture(pie_chart_path, width=Inches(5.5))\n",
    "doc.add_paragraph(\"Pie chart showing sentiment proportions.\")\n",
    "\n",
    "# Word Clouds\n",
    "doc.add_heading(\"Word Clouds\", level=1)\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Positive\")\n",
    "doc.add_picture(positive_wc, width=Inches(5.5))\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Neutral\")\n",
    "doc.add_picture(neutral_wc, width=Inches(5.5))\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Negative\")\n",
    "doc.add_picture(negative_wc, width=Inches(5.5))\n",
    "\n",
    "# Observations\n",
    "doc.add_heading(\"Key Observations\", level=1)\n",
    "doc.add_paragraph(f\"• Most of the texts were classified as **{dominant_sentiment}**.\")\n",
    "doc.add_paragraph(f\"• Positive: {positive_count}\")\n",
    "doc.add_paragraph(f\"• Neutral: {neutral_count}\")\n",
    "doc.add_paragraph(f\"• Negative: {negative_count}\")\n",
    "doc.add_paragraph(\"• The combination of three sentiment models ensures a more reliable classification.\")\n",
    "\n",
    "# Save Report\n",
    "doc.save(report_file)\n",
    "print(f\"✅ DOCX report saved as '{report_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
